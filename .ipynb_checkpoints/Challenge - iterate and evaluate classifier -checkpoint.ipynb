{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab and process the raw data.\n",
    "data_path = (\"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "             \"master/sms_spam_collection/SMSSpamCollection\"\n",
    "            )\n",
    "sms_raw = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
    "sms_raw.columns = ['spam', 'message']\n",
    "\n",
    "# Enumerate our spammy keywords.\n",
    "keywords = ['click', 'offer', 'winner', 'buy', 'free', 'cash', 'urgent']\n",
    "\n",
    "for key in keywords:\n",
    "    sms_raw[str(key)] = sms_raw.message.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    ")\n",
    "\n",
    "sms_raw['allcaps'] = sms_raw.message.str.isupper()\n",
    "sms_raw['spam'] = (sms_raw['spam'] == 'spam')\n",
    "data = sms_raw[keywords + ['allcaps']]\n",
    "target = sms_raw['spam']\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "y_pred = bnb.fit(data, target).predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8916008614501076"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.score(data,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 1\n",
    "\n",
    "Oversampling minority class (spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam       4825\n",
       "message    4825\n",
       "click      4825\n",
       "offer      4825\n",
       "winner     4825\n",
       "buy        4825\n",
       "free       4825\n",
       "cash       4825\n",
       "urgent     4825\n",
       "allcaps    4825\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_raw[sms_raw.spam==False].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     4825\n",
       "False    4825\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab and process the raw data.\n",
    "data_path = (\"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "             \"master/sms_spam_collection/SMSSpamCollection\"\n",
    "            )\n",
    "sms_raw = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
    "sms_raw.columns = ['spam', 'message']\n",
    "\n",
    "# Enumerate our spammy keywords.\n",
    "keywords = ['click', 'offer', 'winner', 'buy', 'free', 'cash', 'urgent']\n",
    "\n",
    "for key in keywords:\n",
    "    sms_raw[str(key)] = sms_raw.message.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    ")    \n",
    "sms_raw['allcaps'] = sms_raw.message.str.isupper()\n",
    "sms_raw['spam'] = (sms_raw['spam'] == 'spam')\n",
    "data = sms_raw[keywords + ['allcaps']]\n",
    "target = sms_raw['spam']\n",
    "\n",
    "\n",
    "# Separate majority and minority classes\n",
    "sms_majority = sms_raw[sms_raw.spam==False]\n",
    "sms_minority = sms_raw[sms_raw.spam==True]\n",
    " \n",
    "# Upsample minority class\n",
    "sms_minority_upsampled = resample(sms_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=4825,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "sms_upsampled = pd.concat([sms_majority, sms_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "sms_upsampled.spam.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6283937823834197"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = sms_upsampled[keywords + ['allcaps']]\n",
    "target1 = sms_upsampled['spam']\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "y_pred = bnb.fit(data1, target1).predict(data1)\n",
    "bnb.score(data1,target1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 5572 points : 604\n"
     ]
    }
   ],
   "source": [
    "bnb.fit(data1,target1)\n",
    "\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 2 \n",
    "\n",
    "Undersample majority class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam       747\n",
       "message    747\n",
       "click      747\n",
       "offer      747\n",
       "winner     747\n",
       "buy        747\n",
       "free       747\n",
       "cash       747\n",
       "urgent     747\n",
       "allcaps    747\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_raw[sms_raw.spam==True].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     747\n",
       "False    747\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab and process the raw data.\n",
    "data_path = (\"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "             \"master/sms_spam_collection/SMSSpamCollection\"\n",
    "            )\n",
    "sms_raw = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
    "sms_raw.columns = ['spam', 'message']\n",
    "\n",
    "# Enumerate our spammy keywords.\n",
    "keywords = ['click', 'offer', 'winner', 'buy', 'free', 'cash', 'urgent']\n",
    "\n",
    "for key in keywords:\n",
    "    sms_raw[str(key)] = sms_raw.message.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    ")    \n",
    "sms_raw['allcaps'] = sms_raw.message.str.isupper()\n",
    "sms_raw['spam'] = (sms_raw['spam'] == 'spam')\n",
    "data = sms_raw[keywords + ['allcaps']]\n",
    "target = sms_raw['spam']\n",
    "\n",
    "\n",
    "# Separate majority and minority classes\n",
    "sms_majority = sms_raw[sms_raw.spam==False]\n",
    "sms_minority = sms_raw[sms_raw.spam==True]\n",
    " \n",
    "# Upsample minority class\n",
    "sms_majority_downsampled = resample(sms_majority, \n",
    "                                 replace=False,     # sample with replacement\n",
    "                                 n_samples=747,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "sms_downsampled = pd.concat([sms_minority, sms_majority_downsampled])\n",
    " \n",
    "# Display new class counts\n",
    "sms_downsampled.spam.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6305220883534136"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = sms_downsampled[keywords + ['allcaps']]\n",
    "target1 = sms_downsampled['spam']\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "y_pred = bnb.fit(data1, target1).predict(data1)\n",
    "bnb.score(data1,target1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 3 \n",
    "\n",
    "Re-vamp keyword list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab and process the raw data.\n",
    "data_path = (\"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "             \"master/sms_spam_collection/SMSSpamCollection\"\n",
    "            )\n",
    "sms_raw = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
    "sms_raw.columns = ['spam', 'message']\n",
    "\n",
    "# Enumerate our spammy keywords.\n",
    "keywords = ['xxx', 'offer', 'ringtone', 'unsubscribe', 'sex', 'donate', 'urgent', 'free', 'baby', 'txt', 'horny']\n",
    "\n",
    "for key in keywords:\n",
    "    sms_raw[str(key)] = sms_raw.message.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    ")\n",
    "\n",
    "sms_raw['allcaps'] = sms_raw.message.str.isupper()\n",
    "sms_raw['spam'] = (sms_raw['spam'] == 'spam')\n",
    "data = sms_raw[keywords + ['allcaps']]\n",
    "target = sms_raw['spam']\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "y_pred = bnb.fit(data, target).predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 5572 points : 542\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9027279253409907"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.score(data,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 4 \n",
    "\n",
    "Holdout group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 30% Holdout: 0.9001196172248804\n",
      "Testing on Sample: 0.9027279253409907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=20)\n",
    "print('With 30% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 5 \n",
    "\n",
    "Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91039427, 0.90501792, 0.91218638, 0.89964158, 0.91935484,\n",
       "       0.90125673, 0.8940754 , 0.89208633, 0.89208633, 0.89928058])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling of Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<Forwarded from 448712404000>Please CALL 08712404000 immediately as there is an urgent message waiting for you.',\n",
       "       'Congratulations - Thanks to a good friend U have WON the Â£2,000 Xmas prize. 2 claim is easy, just call 08712103738 NOW! Only 10p per minute. BT-national-rate',\n",
       "       'Reply with your name and address and YOU WILL RECEIVE BY POST a weeks completely free accommodation at various global locations www.phb1.com ph:08700435505150p'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_raw[sms_raw.spam==True].sample(3)['message'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword List 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     747\n",
      "False    747\n",
      "Name: spam, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7186234817813765"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab and process the raw data.\n",
    "data_path = (\"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "             \"master/sms_spam_collection/SMSSpamCollection\"\n",
    "            )\n",
    "sms_raw = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
    "sms_raw.columns = ['spam', 'message']\n",
    "\n",
    "# Enumerate our spammy keywords.\n",
    "keywords = ['click', 'offer', 'winner', 'buy', 'free', 'cash', 'urgent']\n",
    "\n",
    "for key in keywords:\n",
    "    sms_raw[str(key)] = sms_raw.message.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    ")    \n",
    "sms_raw['allcaps'] = sms_raw.message.str.isupper()\n",
    "sms_raw['spam'] = (sms_raw['spam'] == 'spam')\n",
    "data = sms_raw[keywords + ['allcaps']]\n",
    "target = sms_raw['spam']\n",
    "\n",
    "\n",
    "# Separate majority and minority classes\n",
    "sms_majority = sms_raw[sms_raw.spam==False]\n",
    "sms_minority = sms_raw[sms_raw.spam==True]\n",
    " \n",
    "# Upsample minority class\n",
    "sms_majority_downsampled = resample(sms_majority, \n",
    "                                 replace=False,     # sample with replacement\n",
    "                                 n_samples=747,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "sms_downsampled = pd.concat([sms_minority, sms_majority_downsampled])\n",
    " \n",
    "# Display new class counts\n",
    "print(sms_downsampled.spam.value_counts())\n",
    "\n",
    "data1 = sms_downsampled[keywords + ['allcaps']]\n",
    "target1 = sms_downsampled['spam']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data1, target1, test_size=0.33, random_state=101)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "bnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78      , 0.74      , 0.66      , 0.62      , 0.74      ,\n",
       "       0.7       , 0.68      , 0.72916667, 0.75      , 0.77083333])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, X_test, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword List 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     747\n",
      "False    747\n",
      "Name: spam, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7327935222672065"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab and process the raw data.\n",
    "data_path = (\"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "             \"master/sms_spam_collection/SMSSpamCollection\"\n",
    "            )\n",
    "sms_raw = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
    "sms_raw.columns = ['spam', 'message']\n",
    "\n",
    "# Enumerate our spammy keywords.\n",
    "keywords = ['xxx', 'offer', 'ringtone', 'free', 'baby', 'txt', 'horny']\n",
    "\n",
    "for key in keywords:\n",
    "    sms_raw[str(key)] = sms_raw.message.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    ")    \n",
    "sms_raw['allcaps'] = sms_raw.message.str.isupper()\n",
    "sms_raw['spam'] = (sms_raw['spam'] == 'spam')\n",
    "data = sms_raw[keywords + ['allcaps']]\n",
    "target = sms_raw['spam']\n",
    "\n",
    "\n",
    "# Separate majority and minority classes\n",
    "sms_majority = sms_raw[sms_raw.spam==False]\n",
    "sms_minority = sms_raw[sms_raw.spam==True]\n",
    " \n",
    "# Upsample minority class\n",
    "sms_majority_downsampled = resample(sms_majority, \n",
    "                                 replace=False,     # sample with replacement\n",
    "                                 n_samples=747,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "sms_downsampled = pd.concat([sms_minority, sms_majority_downsampled])\n",
    " \n",
    "# Display new class counts\n",
    "print(sms_downsampled.spam.value_counts())\n",
    "\n",
    "data1 = sms_downsampled[keywords + ['allcaps']]\n",
    "target1 = sms_downsampled['spam']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data1, target1, test_size=0.33, random_state=101)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "bnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72      , 0.68      , 0.74      , 0.7       , 0.74      ,\n",
       "       0.72      , 0.72      , 0.77083333, 0.72916667, 0.8125    ])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, X_test, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword List 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     747\n",
      "False    747\n",
      "Name: spam, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.611336032388664"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab and process the raw data.\n",
    "data_path = (\"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "             \"master/sms_spam_collection/SMSSpamCollection\"\n",
    "            )\n",
    "sms_raw = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
    "sms_raw.columns = ['spam', 'message']\n",
    "\n",
    "# Enumerate our spammy keywords.\n",
    "keywords = ['xxx', 'offer', 'ringtone', 'unsubscribe', 'sex', 'donate', 'urgent']\n",
    "\n",
    "for key in keywords:\n",
    "    sms_raw[str(key)] = sms_raw.message.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    ")    \n",
    "sms_raw['allcaps'] = sms_raw.message.str.isupper()\n",
    "sms_raw['spam'] = (sms_raw['spam'] == 'spam')\n",
    "data = sms_raw[keywords + ['allcaps']]\n",
    "target = sms_raw['spam']\n",
    "\n",
    "\n",
    "# Separate majority and minority classes\n",
    "sms_majority = sms_raw[sms_raw.spam==False]\n",
    "sms_minority = sms_raw[sms_raw.spam==True]\n",
    " \n",
    "# Upsample minority class\n",
    "sms_majority_downsampled = resample(sms_majority, \n",
    "                                 replace=False,     # sample with replacement\n",
    "                                 n_samples=747,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "sms_downsampled = pd.concat([sms_minority, sms_majority_downsampled])\n",
    " \n",
    "# Display new class counts\n",
    "print(sms_downsampled.spam.value_counts())\n",
    "\n",
    "data1 = sms_downsampled[keywords + ['allcaps']]\n",
    "target1 = sms_downsampled['spam']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data1, target1, test_size=0.33, random_state=101)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "bnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58      , 0.52      , 0.64      , 0.56      , 0.72      ,\n",
       "       0.58      , 0.6       , 0.6875    , 0.60416667, 0.625     ])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, X_test, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword List 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     747\n",
      "False    747\n",
      "Name: spam, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.757085020242915"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab and process the raw data.\n",
    "data_path = (\"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "             \"master/sms_spam_collection/SMSSpamCollection\"\n",
    "            )\n",
    "sms_raw = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
    "sms_raw.columns = ['spam', 'message']\n",
    "\n",
    "# Enumerate our spammy keywords.\n",
    "keywords = ['xxx', 'offer', 'sex', 'donate', 'urgent', 'free', 'baby', 'txt', 'horny']\n",
    "\n",
    "for key in keywords:\n",
    "    sms_raw[str(key)] = sms_raw.message.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    ")    \n",
    "sms_raw['allcaps'] = sms_raw.message.str.isupper()\n",
    "sms_raw['spam'] = (sms_raw['spam'] == 'spam')\n",
    "data = sms_raw[keywords + ['allcaps']]\n",
    "target = sms_raw['spam']\n",
    "\n",
    "\n",
    "# Separate majority and minority classes\n",
    "sms_majority = sms_raw[sms_raw.spam==False]\n",
    "sms_minority = sms_raw[sms_raw.spam==True]\n",
    " \n",
    "# Upsample minority class\n",
    "sms_majority_downsampled = resample(sms_majority, \n",
    "                                 replace=False,     # sample with replacement\n",
    "                                 n_samples=747,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "sms_downsampled = pd.concat([sms_minority, sms_majority_downsampled])\n",
    " \n",
    "# Display new class counts\n",
    "print(sms_downsampled.spam.value_counts())\n",
    "\n",
    "data1 = sms_downsampled[keywords + ['allcaps']]\n",
    "target1 = sms_downsampled['spam']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data1, target1, test_size=0.33, random_state=101)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "bnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78      , 0.7       , 0.76      , 0.68      , 0.78      ,\n",
       "       0.76      , 0.68      , 0.85416667, 0.75      , 0.8125    ])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, X_test, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword List 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     747\n",
      "False    747\n",
      "Name: spam, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7388663967611336"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab and process the raw data.\n",
    "data_path = (\"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "             \"master/sms_spam_collection/SMSSpamCollection\"\n",
    "            )\n",
    "sms_raw = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
    "sms_raw.columns = ['spam', 'message']\n",
    "\n",
    "# Enumerate our spammy keywords.\n",
    "keywords = ['congrats', 'private', 'chat', 'prize', \n",
    "           'new', 'contact', 'tone', 'winner']\n",
    "\n",
    "for key in keywords:\n",
    "    sms_raw[str(key)] = sms_raw.message.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    ")    \n",
    "sms_raw['allcaps'] = sms_raw.message.str.isupper()\n",
    "sms_raw['spam'] = (sms_raw['spam'] == 'spam')\n",
    "data = sms_raw[keywords + ['allcaps']]\n",
    "target = sms_raw['spam']\n",
    "\n",
    "\n",
    "# Separate majority and minority classes\n",
    "sms_majority = sms_raw[sms_raw.spam==False]\n",
    "sms_minority = sms_raw[sms_raw.spam==True]\n",
    " \n",
    "# Upsample minority class\n",
    "sms_majority_downsampled = resample(sms_majority, \n",
    "                                 replace=False,     # sample with replacement\n",
    "                                 n_samples=747,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "sms_downsampled = pd.concat([sms_minority, sms_majority_downsampled])\n",
    " \n",
    "# Display new class counts\n",
    "print(sms_downsampled.spam.value_counts())\n",
    "\n",
    "data1 = sms_downsampled[keywords + ['allcaps']]\n",
    "target1 = sms_downsampled['spam']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data1, target1, test_size=0.33, random_state=101)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "bnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82      , 0.64      , 0.78      , 0.7       , 0.76      ,\n",
       "       0.84      , 0.68      , 0.8125    , 0.77083333, 0.58333333])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, X_test, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Keyword List "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     747\n",
      "False    747\n",
      "Name: spam, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9412955465587044"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab and process the raw data.\n",
    "data_path = (\"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "             \"master/sms_spam_collection/SMSSpamCollection\"\n",
    "            )\n",
    "sms_raw = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
    "sms_raw.columns = ['spam', 'message']\n",
    "\n",
    "# Enumerate our spammy keywords.\n",
    "keywords = ['free','txt', 'xxx','contact',\n",
    "            'new','prize','customer','mobile',\n",
    "            'play', 'caller', '0']\n",
    "\n",
    "for key in keywords:\n",
    "    sms_raw[str(key)] = sms_raw.message.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    ")    \n",
    "sms_raw['allcaps'] = sms_raw.message.str.isupper()\n",
    "sms_raw['spam'] = (sms_raw['spam'] == 'spam')\n",
    "data = sms_raw[keywords + ['allcaps']]\n",
    "target = sms_raw['spam']\n",
    "\n",
    "\n",
    "# Separate majority and minority classes\n",
    "sms_majority = sms_raw[sms_raw.spam==False]\n",
    "sms_minority = sms_raw[sms_raw.spam==True]\n",
    " \n",
    "# Upsample minority class\n",
    "sms_majority_downsampled = resample(sms_majority, \n",
    "                                 replace=False,     # sample with replacement\n",
    "                                 n_samples=747,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "sms_downsampled = pd.concat([sms_minority, sms_majority_downsampled])\n",
    " \n",
    "# Display new class counts\n",
    "print(sms_downsampled.spam.value_counts())\n",
    "\n",
    "data1 = sms_downsampled[keywords + ['allcaps']]\n",
    "target1 = sms_downsampled['spam']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data1, target1, test_size=0.33, random_state=101)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "bnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92      , 0.98      , 0.98      , 0.9       , 0.88      ,\n",
       "       0.98      , 0.94      , 0.9375    , 0.9375    , 0.95833333])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, X_test, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words removed \n",
    "words_removed = ['horny', 'baby', 'urgent', 'donate', 'sex', \n",
    "                 'offer','winner', 'chat', 'tone', \n",
    "                 'congrats', 'private', 'unsubscribe'\n",
    "                 'cash','click','buy','win','msg'\n",
    "                 'asap','attempt','vouchers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.959978463747308"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.score(data,target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
